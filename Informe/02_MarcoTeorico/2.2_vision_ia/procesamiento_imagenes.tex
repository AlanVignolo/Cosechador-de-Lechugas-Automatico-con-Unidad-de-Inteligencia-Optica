\subsection{Procesamiento digital de imágenes}

El procesamiento digital de imágenes transforma datos visuales crudos capturados por cámaras en información estructurada procesable por algoritmos de decisión. Una imagen digital se define matemáticamente como una función bidimensional discreta $f(x,y)$ donde las coordenadas espaciales representan posiciones y el valor de la función indica intensidad luminosa. Para imágenes a color en formato RGB:

\begin{equation}
\mathbf{I}(x,y) = \begin{bmatrix} R(x,y) \\ G(x,y) \\ B(x,y) \end{bmatrix} \in [0, 255]^3
\end{equation}

donde $R$, $G$ y $B$ representan los canales rojo, verde y azul respectivamente. Esta codificación permite representar aproximadamente 16.7 millones de colores distintos ($256^3$). La resolución espacial de una imagen de dimensiones $M \times N$ píxeles determina la cantidad de información disponible para el análisis, con cada píxel representando el promedio de la radiancia incidente sobre el área del sensor correspondiente.

\subsubsection{Operaciones de convolución y kernels}

Muchas operaciones de procesamiento de imágenes se basan en la convolución, una operación matemática fundamental que aplica un kernel (también llamado \textit{filtro} o \textit{máscara}) sobre cada píxel de la imagen. Un kernel es una pequeña matriz (típicamente $3 \times 3$, $5 \times 5$ o $7 \times 7$) que define cómo se combinan los valores de los píxeles vecinos para producir un nuevo valor.

La operación de convolución se define matemáticamente como:

\begin{equation}
(I \ast K)(x,y) = \sum_{i=-a}^{a} \sum_{j=-b}^{b} I(x+i, y+j) \cdot K(i,j)
\end{equation}

donde $I$ es la imagen de entrada, $K$ es el kernel de tamaño $(2a+1) \times (2b+1)$, y el resultado $(I \ast K)(x,y)$ representa el valor procesado del píxel en la posición $(x,y)$. En términos simples, para cada píxel se calcula una suma ponderada de los valores de sus píxeles vecinos, donde los pesos están dados por el kernel.

\paragraph{\underline{Elemento estructurante:}}En operaciones morfológicas sobre imágenes binarias (blanco-negro), el kernel se denomina elemento estructurante y define la forma y tamaño del vecindario considerado. Por ejemplo:
\begin{itemize}[label=$\bullet$]
\item Cuadrado $3 \times 3$: afecta los 8 vecinos inmediatos del píxel central
\item Cuadrado $5 \times 5$: afecta un vecindario más amplio (24 píxeles alrededor)
\item Rectangular $7 \times 3$: preferencia direccional (mayor alcance vertical que horizontal)
\end{itemize}

El tamaño y forma del elemento estructurante determinan el alcance y dirección de las operaciones morfológicas aplicadas.

\subsubsection{Espacio de color HSV}

El espacio RGB presenta limitaciones debido a su fuerte correlación entre canales y sensibilidad a variaciones de iluminación. El espacio HSV separa información cromática (matiz H y saturación S) de información de iluminación (valor V), proporcionando robustez frente a cambios de luz. La transformación de RGB a HSV se define mediante las siguientes ecuaciones:

\begin{align}
V &= \max(R, G, B) \\
S &= \begin{cases}
\frac{V - \min(R,G,B)}{V} & \text{si } V \neq 0 \\
0 & \text{si } V = 0
\end{cases} \\
H &= \text{calculado según el canal RGB máximo}
\end{align}

donde $V$ representa el valor (brillo), $S$ la saturación (pureza del color), y $H$ el matiz (tono del color).

\paragraph{\underline{Canal V (valor):}} \textit{El canal $V$ captura la intensidad luminosa independientemente del color, representando el brillo máximo entre los tres canales RGB.} Esta propiedad lo convierte en un descriptor ideal para detectar objetos oscuros contra fondos claros o viceversa. Para detección de elementos de contraste oscuro, el canal $V$ permite segmentación robusta mediante umbralización:

\begin{equation}
\text{Objeto oscuro} \Leftrightarrow V(x,y) < T_V
\end{equation}

donde $T_V$ es un umbral empírico. Valores típicos bajo iluminación controlada son:

\begin{equation}
T_V \in [30, 70]
\end{equation}

Las ventajas incluyen invariancia parcial a color (elementos oscuros se detectan independientemente de matiz), umbralización simple (un único parámetro $T_V$), robustez ante variaciones uniformes de iluminación, y eficiencia computacional al operar sobre un único canal.

\paragraph{\underline{Propiedad de linealidad:}} \textit{Matemáticamente, el canal $V$ satisface una propiedad de linealidad respecto al escalamiento uniforme de intensidad.} Si escalamos una imagen RGB por un factor constante $\alpha > 0$ (por ejemplo, aumentando el brillo), el canal $V$ resultante también se escala por ese mismo factor:

\begin{equation}
V(\alpha \cdot \mathbf{I}_{RGB}) = \alpha \cdot V(\mathbf{I}_{RGB}) \quad \text{para } \alpha > 0
\end{equation}

donde $\mathbf{I}_{RGB}$ representa la imagen en el espacio RGB y $\alpha$ es un factor de escalamiento de intensidad. Esta propiedad permite compensar variaciones uniformes de brillo mediante ajustes proporcionales del umbral $T_V$.

\subsubsection{Umbralización y segmentación}

La umbralización particiona una imagen en regiones de interés comparando intensidades de píxeles contra valores de referencia. En escenarios donde elementos de interés presentan intensidades menores que el fondo, la umbralización binaria inversa resulta esencial:

\begin{equation}
g(x,y) = \begin{cases}
255 & \text{si } f(x,y) < T \\
0 & \text{si } f(x,y) \geq T
\end{cases}
\end{equation}

donde $f(x,y)$ es la intensidad del píxel en la imagen original, $T$ es el umbral de decisión, y $g(x,y)$ es la imagen binaria resultante. Esta operación genera una imagen binaria donde píxeles blancos (255) corresponden a regiones oscuras de la original, permitiendo aislar objetos oscuros sobre fondos claros.

A diferencia de métodos adaptativos como Otsu (que calcula automáticamente el umbral óptimo minimizando la varianza intra-clase), en entornos controlados resulta más efectivo establecer umbrales fijos determinados experimentalmente mediante análisis de histogramas del canal $V$ sobre imágenes representativas, identificando el rango de valores que caracteriza consistentemente los objetos de interés y estableciendo $T$ en el punto que maximiza separación entre objeto y fondo.

\subsubsection{Operaciones morfológicas}

Las operaciones morfológicas manipulan forma y estructura de objetos en imágenes binarias mediante elementos estructurantes, permitiendo eliminar ruido, rellenar huecos y separar objetos conectados.

\paragraph{\underline{Operaciones básicas:}}

\begin{itemize}[label=$\bullet$]
\item Erosión (símbolo $\ominus$): reduce el tamaño de objetos eliminando píxeles del perímetro:
\begin{equation}
(A \ominus B)(x,y) = \min_{(s,t) \in B} \{A(x+s, y+t)\}
\end{equation}
donde $A$ es la imagen binaria y $B$ el elemento estructurante.

\item Dilatación (símbolo $\oplus$): expande objetos añadiendo píxeles al perímetro:
\begin{equation}
(A \oplus B)(x,y) = \max_{(s,t) \in B} \{A(x+s, y+t)\}
\end{equation}
\end{itemize}

\paragraph{\underline{Operaciones compuestas:}}

Estas operaciones básicas se combinan para formar operaciones más complejas:

\begin{itemize}[label=$\bullet$]
\item Apertura (símbolo $\circ$): aplica erosión seguida de dilatación:
\begin{equation}
(A \circ B) = (A \ominus B) \oplus B
\end{equation}
Elimina pequeños objetos y protuberancias manteniendo el tamaño aproximado de objetos grandes.

\item Cierre (símbolo $\bullet$): aplica dilatación seguida de erosión:
\begin{equation}
(A \bullet B) = (A \oplus B) \ominus B
\end{equation}
Rellena huecos pequeños y conecta componentes próximos. El cierre resulta esencial para consolidar regiones fragmentadas durante la segmentación.
\end{itemize}

\paragraph{\underline{Configuración de operaciones:}}

La forma y tamaño del elemento estructurante $B$ determina el comportamiento: cuadrados $3 \times 3$ para operaciones isotrópicas básicas, cuadrados $5 \times 5$ con mayor alcance para eliminar ruido moderado, y rectangulares verticales $7 \times 3$ para conectividad preferencial vertical.

Una secuencia típica de refinamiento morfológico aplica múltiples operaciones iteradas. El término iteraciones (abreviado como \textit{iter.}) indica cuántas veces consecutivas se repite la operación:
\begin{itemize}[label=$\bullet$]
\item Apertura $(3 \times 3, 2 \text{ iter.})$: eliminar ruido puntual aplicando apertura 2 veces
\item Cierre $(3 \times 3, 2 \text{ iter.})$: rellenar huecos pequeños aplicando cierre 2 veces
\item Cierre $(5 \times 5, 2 \text{ iter.})$: conectar regiones próximas con elemento mayor
\item Cierre vertical $(7 \times 3, 1 \text{ iter.})$: unificar objetos verticalmente fragmentados
\end{itemize}

\subsubsection{Calibración espacial}

La calibración establece correspondencia entre coordenadas píxel en imagen y coordenadas físicas en espacio de trabajo, fundamental para convertir mediciones visuales en comandos de movimiento precisos. Para configuraciones donde la cámara observa perpendicular al plano de trabajo a distancia constante, la transformación píxel-a-métrica se aproxima mediante modelo lineal afín:

\begin{equation}
d_{mm} = a \cdot d_{px} + b
\end{equation}

donde $d_{px}$ es distancia en píxeles, $d_{mm}$ distancia física en milímetros, y $a, b$ parámetros de calibración. El coeficiente $a$ representa la escala (mm/píxel) y $b$ un offset sistemático.

Los parámetros se estiman mediante regresión lineal por mínimos cuadrados a partir de pares de correspondencia conocidos $\{(d_{px,i}, d_{mm,i})\}_{i=1}^{N}$, minimizando el error cuadrático:

\begin{equation}
\min_{a,b} \sum_{i=1}^{N} (d_{mm,i} - (a \cdot d_{px,i} + b))^2
\end{equation}

La solución analítica mediante ecuaciones normales proporciona:

\begin{equation}
a = \frac{N\sum d_{px,i}d_{mm,i} - \sum d_{px,i}\sum d_{mm,i}}{N\sum d_{px,i}^2 - (\sum d_{px,i})^2}, \quad b = \frac{\sum d_{mm,i} - a\sum d_{px,i}}{N}
\end{equation}

El procedimiento de calibración coloca marcadores de referencia en posiciones conocidas, captura imagen detectando posiciones en píxeles, mide físicamente distancias entre marcadores, calcula distancias en píxeles entre los mismos marcadores, aplica regresión lineal para estimar parámetros, y valida con mediciones independientes.

La precisión se cuantifica mediante error cuadrático medio: $\text{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(d_{mm,i} - \hat{d}_{mm,i})^2}$ donde $\hat{d}_{mm,i} = a \cdot d_{px,i} + b$ son predicciones del modelo. Valores de RMSE inferiores a 1-2mm resultan aceptables para manipulación agrícola de precisión. El coeficiente de determinación $R^2 = 1 - \frac{\sum (d_{mm,i} - \hat{d}_{mm,i})^2}{\sum (d_{mm,i} - \bar{d}_{mm})^2}$ complementa la evaluación; valores $R^2 > 0.99$ indican excelente ajuste lineal, validando la aproximación del modelo.

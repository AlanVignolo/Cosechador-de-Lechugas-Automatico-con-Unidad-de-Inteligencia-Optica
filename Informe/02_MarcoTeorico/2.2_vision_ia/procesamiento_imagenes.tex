\subsection{Procesamiento Digital de Imágenes}

El procesamiento digital de imágenes transforma datos visuales crudos capturados por cámaras en información estructurada procesable por algoritmos de decisión. Una imagen digital se define matemáticamente como una función bidimensional discreta $f(x,y)$ donde las coordenadas espaciales representan posiciones y el valor de la función indica intensidad luminosa. Para imágenes a color en formato RGB:

\begin{equation}
\mathbf{I}(x,y) = \begin{bmatrix} R(x,y) \\ G(x,y) \\ B(x,y) \end{bmatrix} \in [0, 255]^3
\end{equation}

donde $R$, $G$ y $B$ representan los canales rojo, verde y azul respectivamente. Esta codificación permite representar aproximadamente 16.7 millones de colores distintos ($256^3$). La resolución espacial de una imagen de dimensiones $M \times N$ píxeles determina la cantidad de información disponible para el análisis, con cada píxel representando el promedio de la radiancia incidente sobre el área del sensor correspondiente.

\subsubsection{Espacio de Color HSV}

El espacio RGB presenta limitaciones debido a su fuerte correlación entre canales y sensibilidad a variaciones de iluminación. El espacio HSV separa información cromática (matiz H y saturación S) de información de iluminación (valor V), proporcionando robustez frente a cambios de luz. La transformación de RGB a HSV se define como $V = \max(R, G, B)$, $S = (V - \min(R,G,B))/V$ si $V \neq 0$, y $H$ calculado según cuál componente RGB es máxima.

El canal $V$ (Value) captura la intensidad luminosa independientemente del color, representando el brillo máximo entre los tres canales RGB. Esta propiedad lo convierte en un descriptor ideal para detectar objetos oscuros contra fondos claros o viceversa. Para detección de elementos de contraste oscuro (marcadores negros, cintas de cultivo), el canal $V$ permite segmentación robusta mediante umbralización: $\text{Objeto oscuro} \Leftrightarrow V(x,y) < T_V$ donde $T_V$ es un umbral empírico. En cultivo hidropónico bajo iluminación controlada, valores típicos son $T_V \in [30, 70]$.

Las ventajas incluyen invariancia parcial a color (elementos oscuros se detectan independientemente de matiz), umbralización simple (un único parámetro $T_V$), robustez ante variaciones uniformes de iluminación, y eficiencia computacional al operar sobre un único canal. Matemáticamente, el canal $V$ satisface linealidad: $V(\alpha \cdot \mathbf{I}_{RGB}) = \alpha \cdot V(\mathbf{I}_{RGB})$ para $\alpha > 0$, permitiendo compensar variaciones uniformes de brillo mediante ajustes del umbral.

\subsubsection{Umbralización y Segmentación}

La umbralización particiona una imagen en regiones de interés comparando intensidades de píxeles contra valores de referencia. En escenarios donde elementos de interés presentan intensidades menores que el fondo, la \textbf{umbralización binaria inversa} resulta esencial:

\begin{equation}
g(x,y) = \begin{cases}
255 & \text{si } f(x,y) < T \\
0 & \text{si } f(x,y) \geq T
\end{cases}
\end{equation}

Esta operación genera una imagen binaria donde píxeles blancos (255) corresponden a regiones oscuras de la original, empleada para detectar cintas negras, tubos oscuros y marcadores de contraste. A diferencia de métodos adaptativos como Otsu, en entornos controlados resulta más efectivo establecer umbrales fijos determinados experimentalmente mediante análisis de histogramas del canal $V$ sobre imágenes representativas, identificando el rango de valores que caracteriza consistentemente los objetos de interés y estableciendo $T_V$ en el punto que maximiza separación entre objeto y fondo.

\subsubsection{Operaciones Morfológicas}

Las operaciones morfológicas manipulan forma y estructura de objetos en imágenes binarias mediante elementos estructurantes, permitiendo eliminar ruido, rellenar huecos y separar objetos conectados. La \textbf{erosión} reduce el tamaño de objetos eliminando píxeles del perímetro: $(A \ominus B)(x,y) = \min_{(s,t) \in B} \{A(x+s, y+t)\}$ donde $A$ es la imagen binaria y $B$ el elemento estructurante. La \textbf{dilatación} expande objetos añadiendo píxeles al perímetro: $(A \oplus B)(x,y) = \max_{(s,t) \in B} \{A(x+s, y+t)\}$.

Estas operaciones se combinan formando \textbf{apertura} $(A \circ B) = (A \ominus B) \oplus B$ que elimina pequeños objetos y protuberancias manteniendo tamaño aproximado de objetos grandes, y \textbf{cierre} $(A \bullet B) = (A \oplus B) \ominus B$ que rellena huecos pequeños y conecta componentes próximos. El cierre resulta esencial para consolidar regiones fragmentadas durante la segmentación.

La forma y tamaño del elemento estructurante $B$ determina el comportamiento: cuadrados $3 \times 3$ para operaciones isotrópicas básicas, cuadrados $5 \times 5$ con mayor alcance para eliminar ruido moderado, y rectangulares verticales $7 \times 3$ para conectividad preferencial vertical. Una secuencia típica de refinamiento morfológico aplica: apertura $(3 \times 3, 2 \text{ iter.})$ para eliminar ruido puntual, cierre $(3 \times 3, 2 \text{ iter.})$ para rellenar huecos pequeños, cierre $(5 \times 5, 2 \text{ iter.})$ para conectar regiones próximas, y cierre vertical $(7 \times 3, 1 \text{ iter.})$ para unificar objetos verticalmente fragmentados.

\subsubsection{Calibración Espacial}

La calibración establece correspondencia entre coordenadas píxel en imagen y coordenadas físicas en espacio de trabajo, fundamental para convertir mediciones visuales en comandos de movimiento precisos. Para configuraciones donde la cámara observa perpendicular al plano de trabajo a distancia constante, la transformación píxel-a-métrica se aproxima mediante modelo lineal afín:

\begin{equation}
d_{mm} = a \cdot d_{px} + b
\end{equation}

donde $d_{px}$ es distancia en píxeles, $d_{mm}$ distancia física en milímetros, y $a, b$ parámetros de calibración. El coeficiente $a$ representa la escala (mm/píxel) y $b$ un offset sistemático.

Los parámetros se estiman mediante regresión lineal por mínimos cuadrados a partir de pares de correspondencia conocidos $\{(d_{px,i}, d_{mm,i})\}_{i=1}^{N}$, minimizando el error cuadrático:

\begin{equation}
\min_{a,b} \sum_{i=1}^{N} (d_{mm,i} - (a \cdot d_{px,i} + b))^2
\end{equation}

La solución analítica mediante ecuaciones normales proporciona:

\begin{equation}
a = \frac{N\sum d_{px,i}d_{mm,i} - \sum d_{px,i}\sum d_{mm,i}}{N\sum d_{px,i}^2 - (\sum d_{px,i})^2}, \quad b = \frac{\sum d_{mm,i} - a\sum d_{px,i}}{N}
\end{equation}

El procedimiento de calibración coloca marcadores de referencia en posiciones conocidas, captura imagen detectando posiciones en píxeles, mide físicamente distancias entre marcadores, calcula distancias en píxeles entre los mismos marcadores, aplica regresión lineal para estimar parámetros, y valida con mediciones independientes.

La precisión se cuantifica mediante error cuadrático medio: $\text{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(d_{mm,i} - \hat{d}_{mm,i})^2}$ donde $\hat{d}_{mm,i} = a \cdot d_{px,i} + b$ son predicciones del modelo. Valores de RMSE inferiores a 1-2mm resultan aceptables para manipulación agrícola de precisión. El coeficiente de determinación $R^2 = 1 - \frac{\sum (d_{mm,i} - \hat{d}_{mm,i})^2}{\sum (d_{mm,i} - \bar{d}_{mm})^2}$ complementa la evaluación; valores $R^2 > 0.99$ indican excelente ajuste lineal, validando la aproximación del modelo.

\subsection{Procesamiento digital de imágenes}

El procesamiento digital de imágenes transforma datos visuales crudos capturados por cámaras en información estructurada procesable por algoritmos de decisión. Una imagen digital se define matemáticamente como una función bidimensional discreta $f(x,y)$ donde las coordenadas espaciales representan posiciones y el valor de la función indica intensidad luminosa. Para imágenes a color en formato RGB:

\begin{equation}
\mathbf{I}(x,y) = \begin{bmatrix} R(x,y) \\ G(x,y) \\ B(x,y) \end{bmatrix} \in [0, 255]^3
\end{equation}

donde $R$, $G$ y $B$ representan los canales rojo, verde y azul respectivamente. Esta codificación permite representar aproximadamente 16.7 millones de colores distintos ($256^3$). La resolución espacial de una imagen de dimensiones $M \times N$ píxeles determina la cantidad de información disponible para el análisis, con cada píxel representando el promedio de la radiancia incidente sobre el área del sensor correspondiente.

\subsubsection{Operaciones de convolución y kernels}

Muchas operaciones de procesamiento de imágenes se basan en la convolución, una operación matemática fundamental que aplica un kernel (también llamado filtro o máscara) sobre cada píxel de la imagen. Un kernel es una pequeña matriz (típicamente $3 \times 3$, $5 \times 5$ o $7 \times 7$) que define cómo se combinan los valores de los píxeles vecinos para producir un nuevo valor.

La operación de convolución se define matemáticamente como:

\begin{equation}
(I \ast K)(x,y) = \sum_{i=-a}^{a} \sum_{j=-b}^{b} I(x+i, y+j) \cdot K(i,j)
\end{equation}

donde $I$ es la imagen de entrada, $K$ es el kernel de tamaño $(2a+1) \times (2b+1)$, siendo a y b la mitad del ancho y largo del kernel respectivamente y el resultado $(I \ast K)(x,y)$ representa el valor procesado del píxel en la posición $(x,y)$. En términos simples, para cada píxel se calcula una suma ponderada de los valores de sus píxeles vecinos, donde los pesos están dados por el kernel.

\underline{Elemento estructurante}: En operaciones morfológicas sobre imágenes binarias (blanco-negro), el kernel se denomina elemento estructurante y define la forma y tamaño del vecindario considerado. Por ejemplo:
\begin{itemize}[label=$\bullet$]
\item Cuadrado $3 \times 3$: afecta los 8 vecinos inmediatos del píxel central
\item Cuadrado $5 \times 5$: afecta un vecindario más amplio (24 píxeles alrededor)
\item Rectangular $7 \times 3$: preferencia direccional (mayor alcance vertical que horizontal)
\end{itemize}

El tamaño y forma del elemento estructurante determinan el alcance y dirección de las operaciones morfológicas aplicadas.

\subsubsection{Espacio de color HSV}

El espacio RGB presenta limitaciones debido a su fuerte correlación entre canales y sensibilidad a variaciones de iluminación. El espacio HSV separa información cromática (matiz H y saturación S) de información de iluminación (valor V), proporcionando robustez frente a cambios de luz. La transformación de RGB a HSV se define mediante las siguientes ecuaciones:

\begin{align}
V &= \max(R, G, B) \\
S &= \begin{cases}
\frac{V - \min(R,G,B)}{V} & \text{si } V \neq 0 \\
0 & \text{si } V = 0
\end{cases} \\
H &= \text{calculado según el canal RGB máximo}
\end{align}

donde $V$ representa el valor (brillo), $S$ la saturación (pureza del color), y $H$ el matiz (tono del color).

El canal $V$ captura la intensidad luminosa independientemente del color, representando el brillo máximo entre los tres canales RGB. Esta propiedad lo convierte en un descriptor ideal para detectar objetos oscuros contra fondos claros o viceversa. Para detección de elementos de contraste oscuro, el canal $V$ permite segmentación robusta mediante umbralización:

\begin{equation}
\text{Objeto oscuro} \Leftrightarrow V(x,y) < T_V
\end{equation}

donde $T_V$ es un umbral empírico. 
Las ventajas incluyen invariancia parcial a color (elementos oscuros se detectan independientemente de matiz), umbralización simple (un único parámetro $T_V$), robustez ante variaciones uniformes de iluminación, y eficiencia computacional al operar sobre un único canal.

\underline{Propiedad de linealidad:} Matemáticamente, el canal $V$ satisface una propiedad de linealidad respecto al escalamiento uniforme de intensidad. 
Si se escala una imagen RGB por un factor constante $\alpha > 0$ (por ejemplo, al aumentar el brillo), el canal $V$ resultante también se escala por ese mismo factor. 
Sin embargo, en la práctica, este comportamiento puede verse afectado por el fenómeno de \textit{saturación}, dado que los valores de intensidad se representan en un rango finito ($0$--$255$). 
Cuando el producto $\alpha \cdot V$ supera 255, el valor se trunca en dicho límite, lo que provoca pérdida de información y rompe la reversibilidad de la transformación.
%\underline{Propiedad de linealidad:} Matemáticamente, el canal $V$ satisface una propiedad de linealidad respecto al escalamiento uniforme de intensidad. Si escalamos una imagen RGB por un factor constante $\alpha > 0$ (por ejemplo, aumentando el brillo), el canal $V$ resultante también se escala por ese mismo factor:

\begin{equation}
V(\alpha \cdot \mathbf{I}_{RGB}) = \alpha \cdot V(\mathbf{I}_{RGB}) \quad \text{para } \alpha > 0
\end{equation}

donde $\mathbf{I}_{RGB}$ representa la imagen en el espacio RGB y $\alpha$ es un factor de escalamiento de intensidad. Esta propiedad permite compensar variaciones uniformes de brillo mediante ajustes proporcionales del umbral $T_V$.

\subsubsection{Umbralización y segmentación}

La umbralización particiona una imagen en regiones de interés comparando intensidades de píxeles contra valores de referencia. En escenarios donde elementos de interés presentan intensidades menores que el fondo, la umbralización binaria inversa resulta esencial:

\begin{equation}
g(x,y) = \begin{cases}
255 & \text{si } f(x,y) < T \\
0 & \text{si } f(x,y) \geq T
\end{cases}
\end{equation}

donde $f(x,y)$ es la intensidad del píxel en la imagen original, $T$ es el umbral de decisión, y $g(x,y)$ es la imagen binaria resultante. Esta operación genera una imagen binaria donde píxeles blancos (255) corresponden a regiones oscuras de la original, permitiendo aislar objetos oscuros sobre fondos claros.

A diferencia de métodos adaptativos, en entornos controlados resulta más efectivo establecer umbrales fijos determinados experimentalmente mediante análisis de histogramas del canal $V$ sobre imágenes representativas, identificando el rango de valores que caracteriza consistentemente los objetos de interés y estableciendo $T$ en el punto que maximiza separación entre objeto y fondo.

\subsubsection{Operaciones morfológicas}

Las operaciones morfológicas manipulan forma y estructura de objetos en imágenes binarias mediante elementos estructurantes, permitiendo eliminar ruido, rellenar huecos y separar objetos conectados.\\

Operaciones básicas:

\begin{itemize}[label=$\bullet$]
\item Erosión (símbolo $\ominus$): reduce el tamaño de objetos eliminando píxeles del perímetro:
\begin{equation}
(A \ominus B)(x,y) = \min_{(s,t) \in B} \{A(x+s, y+t)\}
\label{eq:erosion_morf}
\end{equation}
donde $A$ es la imagen binaria y $B$ el elemento estructurante.

\item Dilatación (símbolo $\oplus$): expande objetos añadiendo píxeles al perímetro:
\begin{equation}
(A \oplus B)(x,y) = \max_{(s,t) \in B} \{A(x+s, y+t)\}
\label{eq:dilatacion_morf}
\end{equation}
\end{itemize}

Operaciones compuestas:
\noindent
Estas operaciones básicas se combinan para formar operaciones más complejas:

\begin{itemize}[label=$\bullet$]
\item Apertura (símbolo $\circ$): aplica erosión seguida de dilatación:
\begin{equation}
(A \circ B) = (A \ominus B) \oplus B
\label{eq:apertura_morf}
\end{equation}
Elimina pequeños objetos y protuberancias manteniendo el tamaño aproximado de objetos grandes.

\item Cierre (símbolo $\bullet$): aplica dilatación seguida de erosión:
\begin{equation}
(A \bullet B) = (A \oplus B) \ominus B
\label{eq:cierre_morf}
\end{equation}
Rellena huecos pequeños y conecta componentes próximos. El cierre resulta esencial para consolidar regiones fragmentadas durante la segmentación. \\
\end{itemize}
La forma y tamaño del elemento estructurante $B$ determina el comportamiento: cuadrados $3 \times 3$ para operaciones isotrópicas básicas, cuadrados $5 \times 5$ con mayor alcance para eliminar ruido moderado, y rectangulares verticales $7 \times 3$ para conectividad preferencial vertical.

Una secuencia típica de refinamiento morfológico aplica múltiples operaciones iteradas. El término iteraciones (abreviado como iter.) indica cuántas veces consecutivas se repite la operación:
\begin{itemize}[label=$\bullet$]
\item Apertura $(3 \times 3, 2 \text{ iter.})$: eliminar ruido puntual aplicando apertura 2 veces
\item Cierre $(3 \times 3, 2 \text{ iter.})$: rellenar huecos pequeños aplicando cierre 2 veces
\item Cierre $(5 \times 5, 2 \text{ iter.})$: conectar regiones próximas con elemento mayor
\item Cierre vertical $(7 \times 3, 1 \text{ iter.})$: unificar objetos verticalmente fragmentados
\end{itemize}

\subsubsection{Calibración espacial}

La calibración establece correspondencia entre coordenadas píxel en imagen y coordenadas físicas en espacio de trabajo, fundamental para convertir mediciones visuales en comandos de movimiento precisos. Para configuraciones donde la cámara observa perpendicular al plano de trabajo a distancia constante, la transformación píxel-a-métrica se aproxima mediante modelo lineal afín:

\begin{equation}
d_{mm} = a \cdot d_{px} + b
\end{equation}

donde $d_{px}$ es distancia en píxeles, $d_{mm}$ distancia física en milímetros, y $a, b$ parámetros de calibración. El coeficiente $a$ representa la escala (mm/píxel) y $b$ un offset sistemático.

Los parámetros se estiman mediante regresión lineal por mínimos cuadrados a partir de pares de correspondencia conocidos $\{(d_{px,i}, d_{mm,i})\}_{i=1}^{N}$, minimizando el error cuadrático:

\begin{equation}
\min_{a,b} \sum_{i=1}^{N} (d_{mm,i} - (a \cdot d_{px,i} + b))^2
\end{equation}

La solución analítica mediante ecuaciones normales proporciona:

\begin{equation}
a = \frac{N\sum d_{px,i}d_{mm,i} - \sum d_{px,i}\sum d_{mm,i}}{N\sum d_{px,i}^2 - (\sum d_{px,i})^2}, \quad b = \frac{\sum d_{mm,i} - a\sum d_{px,i}}{N}
\end{equation}

El procedimiento de calibración coloca marcadores de referencia en posiciones conocidas, captura imagen detectando posiciones en píxeles, mide físicamente distancias entre marcadores, calcula distancias en píxeles entre los mismos marcadores, aplica regresión lineal para estimar parámetros, y valida con mediciones independientes.

La precisión se cuantifica mediante error cuadrático medio: $\text{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(d_{mm,i} - \hat{d}_{mm,i})^2}$ donde $\hat{d}_{mm,i} = a \cdot d_{px,i} + b$ son predicciones del modelo. Valores de RMSE inferiores a 1-2mm resultan aceptables para manipulación de precisión. El coeficiente de determinación $R^2 = 1 - \frac{\sum (d_{mm,i} - \hat{d}_{mm,i})^2}{\sum (d_{mm,i} - \bar{d}_{mm})^2}$ complementa la evaluación; valores $R^2 > 0.99$ indican excelente ajuste lineal, validando la aproximación del modelo.
